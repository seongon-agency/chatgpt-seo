{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEmCAV7yDApJz+EktxnL10",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seongon-agency/chatgpt-seo/blob/main/chatgpt_html_to_markdown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCKoGivTxP1p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fe5693-7cdd-46f1-abb1-55144148b5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html_to_markdown in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.13.4 in /usr/local/lib/python3.12/dist-packages (from html_to_markdown) (4.13.4)\n",
            "Requirement already satisfied: nh3>=0.3 in /usr/local/lib/python3.12/dist-packages (from html_to_markdown) (0.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->html_to_markdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->html_to_markdown) (4.14.1)\n",
            "Converted 'prompt_id_002 reasoning.html' to 'prompt_id_002 reasoning.md'\n",
            "Converted 'prompt_id_001 reasoning.html' to 'prompt_id_001 reasoning.md'\n"
          ]
        }
      ],
      "source": [
        "!pip install html_to_markdown\n",
        "import html_to_markdown\n",
        "import os\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        input_dir = \"html_file\" # Input directory containing HTML files\n",
        "        output_dir = \"markdown_file\" # Output directory for Markdown files\n",
        "\n",
        "        # Ensure the output directory exists\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Get a list of all HTML files in the input directory\n",
        "        html_files = [f for f in os.listdir(input_dir) if f.endswith(\".html\")]\n",
        "\n",
        "        if not html_files:\n",
        "            print(f\"No HTML files found in the directory: {input_dir}\")\n",
        "            return\n",
        "\n",
        "        for html_file_name in html_files:\n",
        "            html_file_path = os.path.join(input_dir, html_file_name)\n",
        "            markdown_file_name = os.path.splitext(html_file_name)[0] + \".md\"\n",
        "            markdown_file_path = os.path.join(output_dir, markdown_file_name)\n",
        "\n",
        "            with open(html_file_path, \"r\", encoding=\"utf-8\") as html_file:\n",
        "                html_content = html_file.read()\n",
        "\n",
        "            # Use BeautifulSoup to parse HTML and remove image elements\n",
        "            soup = BeautifulSoup(html_content, 'html.parser')\n",
        "            for img in soup.find_all('img'):\n",
        "                img.decompose()\n",
        "            # Also remove SVG elements\n",
        "            for svg in soup.find_all('svg'):\n",
        "                svg.decompose()\n",
        "\n",
        "            cleaned_html_content = str(soup)\n",
        "\n",
        "            # Convert HTML to Markdown using html_to_markdown library\n",
        "            markdown_content = html_to_markdown.convert_to_markdown(cleaned_html_content)\n",
        "\n",
        "            # Remove everything before \"You said:\" or \"Bạn đã nói:\"\n",
        "            markdown_content = re.sub(r'^.*?(?=You said:|Bạn đã nói:)', '', markdown_content, flags=re.DOTALL)\n",
        "\n",
        "            # Convert markdown links to just URLs\n",
        "            markdown_content = re.sub(r'\\[([^\\]]+)\\](\\(https?://[^\\)]+\\))', r'\\2', markdown_content)\n",
        "\n",
        "            # If the filename contains \"product\", keep only the part after the last \"Sources\" or \"Nguồn\"\n",
        "            if \"product\" in html_file_name.lower():\n",
        "                match = re.search(r'.*(Sources|Nguồn):?(.*)', markdown_content, re.DOTALL | re.IGNORECASE)\n",
        "                if match:\n",
        "                    markdown_content = match.group(1) + match.group(2).strip() # Keep \"Sources\" or \"Nguồn\" and the content after it\n",
        "                else:\n",
        "                    markdown_content = \"\" # Or handle cases where 'Sources'/'Nguồn' is not found\n",
        "\n",
        "\n",
        "            # Write the cleaned Markdown content to the output file\n",
        "            with open(markdown_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
        "                md_file.write(markdown_content)\n",
        "\n",
        "            print(f\"Converted '{html_file_name}' to '{markdown_file_name}'\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Make sure the input directory '{input_dir}' exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5BeQzUQAzFyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAhzQJc9JrSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAhzQc9JrSy",
        "outputId": "c790429f-61be-49a6-851e-f932e9056b06"
      },
      "source": [
        "# Zip the markdown-files folder\n",
        "!zip -r markdown_file.zip markdown_file\n",
        "\n",
        "# Display a message to the user\n",
        "print(\"The 'markdown-files' folder has been zipped as 'markdown-files.zip'. You can download it from the file browser.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: markdown_file/ (stored 0%)\n",
            "  adding: markdown_file/prompt_id_009 reasoning.md (deflated 59%)\n",
            "  adding: markdown_file/prompt_id_021 reasoning.md (deflated 58%)\n",
            "  adding: markdown_file/prompt_id_005 reasoning.md (deflated 56%)\n",
            "  adding: markdown_file/prompt_id_017 reasoning.md (deflated 60%)\n",
            "  adding: markdown_file/prompt_id_002 reasoning.md (deflated 52%)\n",
            "  adding: markdown_file/prompt_id_003 reasoning.md (deflated 55%)\n",
            "  adding: markdown_file/prompt_id_004 reasoning.md (deflated 59%)\n",
            "  adding: markdown_file/prompt_id_006 reasoning.md (deflated 55%)\n",
            "  adding: markdown_file/prompt_id_014 reasoning.md (deflated 60%)\n",
            "  adding: markdown_file/prompt_id_010 reasoning.md (deflated 55%)\n",
            "  adding: markdown_file/prompt_id_019 reasoning.md (deflated 58%)\n",
            "  adding: markdown_file/prompt_id_015 reasoning.md (deflated 62%)\n",
            "  adding: markdown_file/prompt_id_011 reasoning.md (deflated 53%)\n",
            "  adding: markdown_file/prompt_id_016 reasoning.md (deflated 57%)\n",
            "  adding: markdown_file/prompt_id_007 reasoning.md (deflated 61%)\n",
            "  adding: markdown_file/prompt_id_008 reasoning.md (deflated 59%)\n",
            "  adding: markdown_file/prompt_id_018 reasoning.md (deflated 62%)\n",
            "  adding: markdown_file/prompt_id_001 reasoning.md (deflated 58%)\n",
            "The 'markdown-files' folder has been zipped as 'markdown-files.zip'. You can download it from the file browser.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JVbH-mMmKLhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dde5fa1b",
        "outputId": "f29957b6-c4e7-4205-ee04-744e4de2ce75"
      },
      "source": [
        "!pip install html_to_markdown\n",
        "import html_to_markdown\n",
        "import os\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        input_dir = \"html-files\" # Input directory containing HTML files\n",
        "        output_dir = \"prompt_011\" # Output directory for Markdown files\n",
        "\n",
        "        # Ensure the output directory exists\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Get a list of all HTML files in the input directory that contain \"prompt_id_011\"\n",
        "        html_files = [f for f in os.listdir(input_dir) if f.endswith(\".html\") and \"prompt_id_011\" in f]\n",
        "\n",
        "        if not html_files:\n",
        "            print(f\"No HTML files containing 'prompt_id_011' found in the directory: {input_dir}\")\n",
        "            return\n",
        "\n",
        "        for html_file_name in html_files:\n",
        "            html_file_path = os.path.join(input_dir, html_file_name)\n",
        "            markdown_file_name = os.path.splitext(html_file_name)[0] + \".md\"\n",
        "            markdown_file_path = os.path.join(output_dir, markdown_file_name)\n",
        "\n",
        "            with open(html_file_path, \"r\", encoding=\"utf-8\") as html_file:\n",
        "                html_content = html_file.read()\n",
        "\n",
        "            # Use BeautifulSoup to parse HTML and remove image elements\n",
        "            soup = BeautifulSoup(html_content, 'html.parser')\n",
        "            for img in soup.find_all('img'):\n",
        "                img.decompose()\n",
        "            # Also remove SVG elements\n",
        "            for svg in soup.find_all('svg'):\n",
        "                svg.decompose()\n",
        "\n",
        "            cleaned_html_content = str(soup)\n",
        "\n",
        "            # Convert HTML to Markdown using html_to_markdown library\n",
        "            markdown_content = html_to_markdown.convert_to_markdown(cleaned_html_content)\n",
        "\n",
        "            # Remove everything before \"You said:\" or \"Bạn đã nói:\"\n",
        "            markdown_content = re.sub(r'^.*?(?=You said:|Bạn đã nói:)', '', markdown_content, flags=re.DOTALL)\n",
        "\n",
        "            # Convert markdown links to just URLs\n",
        "            markdown_content = re.sub(r'\\[([^\\]]+)\\](\\(https?://[^\\)]+\\))', r'\\2', markdown_content)\n",
        "\n",
        "\n",
        "            # Write the cleaned Markdown content to the output file\n",
        "            with open(markdown_file_path, \"w\", encoding=\"utf-8\") as md_file:\n",
        "                md_file.write(markdown_content)\n",
        "\n",
        "            print(f\"Converted '{html_file_name}' to '{markdown_file_name}'\")\n",
        "\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Make sure the input directory '{input_dir}' exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html_to_markdown in /usr/local/lib/python3.12/dist-packages (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.13.4 in /usr/local/lib/python3.12/dist-packages (from html_to_markdown) (4.13.4)\n",
            "Requirement already satisfied: nh3>=0.3 in /usr/local/lib/python3.12/dist-packages (from html_to_markdown) (0.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->html_to_markdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.4->html_to_markdown) (4.14.1)\n",
            "Converted 'prompt_id_011 (8_18_2025) product2.html' to 'prompt_id_011 (8_18_2025) product2.md'\n",
            "Converted 'prompt_id_011 (8_18_2025) product1.html' to 'prompt_id_011 (8_18_2025) product1.md'\n",
            "Converted 'prompt_id_011 (8_18_2025) citation.html' to 'prompt_id_011 (8_18_2025) citation.md'\n",
            "Converted 'prompt_id_011 (8_18_2025) general.html' to 'prompt_id_011 (8_18_2025) general.md'\n"
          ]
        }
      ]
    }
  ]
}